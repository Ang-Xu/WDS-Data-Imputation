{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from _utils import *\n",
    "from config import *\n",
    "\n",
    "import time\n",
    "import argparse\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import sparse\n",
    "from scipy.sparse.linalg import spsolve as spsolve\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class args_config():\n",
    "    def __init__(self, dataset_name):\n",
    "        self.model_name = 'HaLRTC'\n",
    "        self.model_result_save_path = os.path.join(result_folder_path, self.model_name)\n",
    "        create_folder(self.model_result_save_path)\n",
    "\n",
    "        self.dataset_name = dataset_name\n",
    "        self.dataset_result_save_path = os.path.join(self.model_result_save_path, self.dataset_name)\n",
    "        create_folder(self.dataset_result_save_path)\n",
    "    \n",
    "    def experiment_config(self, experiment_name):\n",
    "        self.experiment_result_save_path = os.path.join(self.dataset_result_save_path, experiment_name)\n",
    "        create_folder(self.experiment_result_save_path)\n",
    "\n",
    "        data_complete_path = os.path.join(self.experiment_result_save_path, 'data_complete.csv')\n",
    "        best_data_complete_path = os.path.join(self.experiment_result_save_path, 'best_data_complete.csv')\n",
    "        metrics_analysis_path = os.path.join(self.experiment_result_save_path, 'metrics_analysis')\n",
    "        plt_result_path = os.path.join(self.experiment_result_save_path, 'plt_result.png')\n",
    "        final_complete_save_path = os.path.join(self.experiment_result_save_path, 'final_complete.csv')\n",
    "        create_folder([metrics_analysis_path])\n",
    "        \n",
    "        parser = argparse.ArgumentParser(description='data complete configs')\n",
    "        parser.add_argument('--data_complete_path', type=str, default=data_complete_path)\n",
    "        parser.add_argument('--best_data_complete_path', type=str, default=best_data_complete_path)\n",
    "        parser.add_argument('--metrics_analysis_path', type=str, default=metrics_analysis_path)\n",
    "        parser.add_argument('--plt_result_path', type=str, default=plt_result_path)\n",
    "        parser.add_argument('--final_complete_save_path', type=str, default=final_complete_save_path)\n",
    "        args = parser.parse_known_args()[0]\n",
    "        return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_sim_args = args_config('flow_sim')\n",
    "flow_zcity_args = args_config('flow_zcity')\n",
    "pres_sim_args = args_config('pres_sim')\n",
    "pres_zcity_args = args_config('pres_zcity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_Psi(dim_time, time_lags):\n",
    "    Psis = []\n",
    "    max_lag = np.max(time_lags)\n",
    "    for i in range(len(time_lags) + 1):\n",
    "        row = np.arange(0, dim_time - max_lag)  \n",
    "        if i == 0:\n",
    "            col = np.arange(0, dim_time - max_lag) + max_lag\n",
    "        else:\n",
    "            col = np.arange(0, dim_time - max_lag) + max_lag - time_lags[i - 1]\n",
    "        data = np.ones(dim_time - max_lag)\n",
    "        Psi = sparse.coo_matrix((data, (row, col)), shape = (dim_time - max_lag, dim_time))\n",
    "        Psis.append(Psi)\n",
    "    return Psis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_result(it, tol, var, var_hat):\n",
    "    print('Iter: {}'.format(it))\n",
    "    print('Tolerance: {:.6}'.format(tol))\n",
    "    num = len(var)\n",
    "    mape = compute_mape(var, var_hat)\n",
    "    rmse = compute_rmse(var, var_hat)\n",
    "    smape = compute_smape(var, var_hat)\n",
    "    print('complete Num: {}'.format(num))\n",
    "    print('complete MAPE: {:.6}'.format(mape))\n",
    "    print('complete RMSE: {:.6}'.format(rmse))\n",
    "    print('complete SMAPE: {:.6}'.format(smape))\n",
    "    return mape, rmse, smape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_true_metrics(raw_data_value, denorm_sparse_value, denorm_data_complete_value):\n",
    "    pos_test = np.where((raw_data_value != 0) & (denorm_sparse_value == 0))\n",
    "    true_mape = compute_mape(raw_data_value[pos_test], denorm_data_complete_value[pos_test])\n",
    "    true_rmse = compute_rmse(raw_data_value[pos_test], denorm_data_complete_value[pos_test])\n",
    "    true_smape = compute_smape(raw_data_value[pos_test], denorm_data_complete_value[pos_test])\n",
    "    return true_mape, true_rmse, true_smape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_data_after_preprocess(best_data_complete_path, data_after_preprocess_path, data_after_complete_path):\n",
    "    best_data_complete_df = read_csv_data(best_data_complete_path)\n",
    "    data_after_preprocess_df = read_csv_data(data_after_preprocess_path)\n",
    "    data_after_preprocess_df = data_after_preprocess_df.astype('float64')\n",
    "    zero_indices = np.where(data_after_preprocess_df == 0)\n",
    "    zero_indices = list(zip(zero_indices[0], zero_indices[1]))\n",
    "    for zero_index in zero_indices:\n",
    "        data_after_preprocess_df.iloc[zero_index[0], zero_index[1]] = best_data_complete_df.iloc[zero_index[0], zero_index[1]]\n",
    "    data_after_preprocess_df.to_csv(data_after_complete_path, index=True, header=True)\n",
    "    print('Data after complete saved in {}'.format(data_after_complete_path))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svt(mat, tau):\n",
    "    u, s, v = np.linalg.svd(mat, full_matrices = False)\n",
    "    vec = s - tau\n",
    "    vec[vec < 0] = 0\n",
    "    return np.matmul(np.matmul(u, np.diag(vec)), v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HaLRTC_imputer(dense_tensor, sparse_tensor, alpha: list, rho: float, epsilon: float, maxiter: int):\n",
    "    dim = np.array(sparse_tensor.shape)\n",
    "    if np.isnan(sparse_tensor).any() == False:\n",
    "        pos_miss = np.where(sparse_tensor == 0)\n",
    "        pos_test = np.where((dense_tensor != 0) & (sparse_tensor == 0))\n",
    "    elif np.isnan(sparse_tensor).any() == True:\n",
    "        pos_test = np.where((dense_tensor != 0) & (np.isnan(sparse_tensor)))\n",
    "        sparse_tensor[np.isnan(sparse_tensor)] = 0\n",
    "        pos_miss = np.where(sparse_tensor == 0)\n",
    "    dense_test = dense_tensor[pos_test]\n",
    "    del dense_tensor\n",
    "    tensor_hat = sparse_tensor.copy()\n",
    "    B = [np.zeros(sparse_tensor.shape) for _ in range(len(dim))]\n",
    "    Y = [np.zeros(sparse_tensor.shape) for _ in range(len(dim))]\n",
    "    last_ten = sparse_tensor.copy()\n",
    "    snorm = np.linalg.norm(sparse_tensor)\n",
    "    \n",
    "    it = 0\n",
    "    while True:\n",
    "        rho = min(rho * 1.05, 1e5)\n",
    "        for k in range(len(dim)):\n",
    "            B[k] = mat2ten(svt(ten2mat(tensor_hat + Y[k] / rho, k), alpha[k] / rho), dim, k)\n",
    "        tensor_hat[pos_miss] = ((sum(B) - sum(Y) / rho) / 3)[pos_miss]\n",
    "        for k in range(len(dim)):\n",
    "            Y[k] = Y[k] - rho * (B[k] - tensor_hat)\n",
    "        tol = np.linalg.norm((tensor_hat - last_ten)) / snorm\n",
    "        last_ten = tensor_hat.copy()\n",
    "        it += 1\n",
    "        if it % 50 == 0:\n",
    "            print('Iter: {}'.format(it))\n",
    "            print('Tolerance: {:.6}'.format(tol))\n",
    "            print('MAPE: {:.6}'.format(compute_mape(dense_test, tensor_hat[pos_test])))\n",
    "            print('RMSE: {:.6}'.format(compute_rmse(dense_test, tensor_hat[pos_test])))\n",
    "            print()\n",
    "        if (tol < epsilon) or (it >= maxiter):\n",
    "            if it >= 30:\n",
    "                break\n",
    "    \n",
    "    tensor_hat[tensor_hat < 1] = 1\n",
    "    print_result(it, tol, dense_test, tensor_hat[pos_test])\n",
    "    return tensor_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HaLRTC_dataComplete():\n",
    "\n",
    "    def __init__(self, dataset_name, experiment_name, experiment_args):\n",
    "        if dataset_name == 'flow_sim':\n",
    "            self.raw_dataset_path = flow_sim_path\n",
    "        elif dataset_name == 'pres_sim':\n",
    "            self.raw_dataset_path = pres_sim_path\n",
    "        elif dataset_name == 'flow_zcity':\n",
    "            self.raw_dataset_path = flow_zcity_path\n",
    "        elif dataset_name == 'pres_zcity':\n",
    "            self.raw_dataset_path = pres_zcity_path\n",
    "\n",
    "        self.raw_data_df = read_csv_data(self.raw_dataset_path)\n",
    "        self.experiment_args = experiment_args\n",
    "        \n",
    "        self.data_norm_for_completing_path = os.path.join(dataset_sparse_path, dataset_name, 'data_norm_for_completing.csv')\n",
    "        self.sparse_mat_for_completing_path = os.path.join(dataset_sparse_path, dataset_name, experiment_name, 'sparse_mat_for_completing.csv')\n",
    "        self.denorm_sparse_for_completing_path = os.path.join(dataset_sparse_path, dataset_name, experiment_name, 'denorm_sparse_for_completing.csv')\n",
    "\n",
    "        self.data_complete_path = self.experiment_args.data_complete_path\n",
    "        self.best_data_complete_path = self.experiment_args.best_data_complete_path\n",
    "        self.metrics_analysis_path = self.experiment_args.metrics_analysis_path\n",
    "        self.plt_result_path = self.experiment_args.plt_result_path\n",
    "        self.final_complete_save_path = self.experiment_args.final_complete_save_path\n",
    "\n",
    "        self._prepareForImputation()\n",
    "        return\n",
    "    \n",
    "    def _prepareForImputation(self):\n",
    "        self.norm_data_df = read_csv_data(self.data_norm_for_completing_path)\n",
    "        self.dense_mat = self.norm_data_df.values\n",
    "        self.dense_tensor = self.dense_mat.T.reshape([self.dense_mat.shape[1], -1, int(24*60/15)]).transpose(0, 2, 1)\n",
    "\n",
    "        self.sparse_mat_df = read_csv_data(self.sparse_mat_for_completing_path)\n",
    "        self.sparse_mat = self.sparse_mat_df.T.values\n",
    "        self.sparse_tensor = self.sparse_mat.reshape([self.dense_mat.shape[1], -1, int(24*60/15)]).transpose(0, 2, 1)\n",
    "        self.denorm_sparse_mat_df = read_csv_data(self.denorm_sparse_for_completing_path)\n",
    "        return\n",
    "\n",
    "    def halrtc_complete(self):\n",
    "        metrics_all_sensors_df = pd.DataFrame(columns=['MAPE', 'RMSE', 'SMAPE'])\n",
    "        metrics_single_sensor_df = pd.DataFrame(columns=self.raw_data_df.columns)\n",
    "        \n",
    "        start = time.time()\n",
    "        alpha = np.ones(3) / 3\n",
    "        rho = 1e-5\n",
    "        epsilon = 1e-4\n",
    "        maxiter = 200\n",
    "        self.tensor_hat = HaLRTC_imputer(self.dense_tensor, self.sparse_tensor, alpha, rho, epsilon, maxiter)\n",
    "        self.mat_hat = ten2mat(self.tensor_hat, 0)\n",
    "        self.data_complete_df = pd.DataFrame(self.mat_hat.T, index=self.norm_data_df.index, columns=self.norm_data_df.columns)\n",
    "        self.denorm_data_complete_df = reverse_one2hundred_normalization(self.data_complete_df, self.raw_data_df)\n",
    "        \n",
    "        self.denorm_data_complete_df = self.denorm_data_complete_df.round(3)\n",
    "        self.denorm_data_complete_df.to_csv(self.data_complete_path, index=True, header=True)\n",
    "            \n",
    "        mape_all_sensors, rmse_all_sensors, smape_all_sensors = compute_true_metrics(self.raw_data_df.values, self.denorm_sparse_mat_df.values, self.denorm_data_complete_df.values)  \n",
    "        print('MAPE: %.6f, RMSE: %.6f, SMAPE: %.6f' % (mape_all_sensors, rmse_all_sensors, smape_all_sensors))\n",
    "        self.denorm_data_complete_df.to_csv(self.best_data_complete_path, index=True, header=True)\n",
    "\n",
    "        mape_single_sensor_list, rmse_single_sensor_list, smape_single_sensor_list = result_analysis(self.raw_data_df, self.denorm_sparse_mat_df, self.denorm_data_complete_df)\n",
    "        metrics_all_sensors_df.loc['all_sensors'] = [mape_all_sensors, rmse_all_sensors, smape_all_sensors]\n",
    "        metrics_single_sensor_df.loc['MAPE'] = mape_single_sensor_list\n",
    "        metrics_single_sensor_df.loc['RMSE'] = rmse_single_sensor_list\n",
    "        metrics_single_sensor_df.loc['SMAPE'] = smape_single_sensor_list\n",
    "        metrics_single_sensor_df.to_csv(os.path.join(self.metrics_analysis_path, 'metrics_single_sensor.csv'), index=True, header=True)\n",
    "        metrics_all_sensors_df.to_csv(os.path.join(self.metrics_analysis_path, 'metrics_all_sensors.csv'), index=True, header=True)\n",
    "        end = time.time()\n",
    "        print('Running time: %d seconds.' % (end - start))\n",
    "        return mape_single_sensor_list, rmse_single_sensor_list, smape_single_sensor_list\n",
    "    \n",
    "    def run(self):\n",
    "        print('\\n--------------------------- Beginning ---------------------------')\n",
    "        best_mape_single_sensor_list, best_rmse_single_sensor_list, best_smape_single_sensor_list = self.halrtc_complete()\n",
    "        fill_data_after_preprocess(self.best_data_complete_path, self.raw_dataset_path, self.final_complete_save_path)\n",
    "        plt_result(self.raw_data_df, read_csv_data(self.best_data_complete_path), self.denorm_sparse_mat_df, self.plt_result_path,\n",
    "                   best_mape_single_sensor_list, best_rmse_single_sensor_list, best_smape_single_sensor_list)\n",
    "        print('\\n--------------------------- Ending ---------------------------')       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 30% Random Missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'random_0.3'\n",
    "dataset_name_list = ['flow_sim', 'flow_zcity', 'pres_sim', 'pres_zcity']\n",
    "\n",
    "for dataset_name in dataset_name_list:\n",
    "    \n",
    "    if dataset_name == 'flow_sim':\n",
    "        experiment_args = flow_sim_args.experiment_config(experiment_name)\n",
    "    elif dataset_name == 'flow_zcity':\n",
    "        experiment_args = flow_zcity_args.experiment_config(experiment_name)\n",
    "    elif dataset_name == 'pres_sim':\n",
    "        experiment_args = pres_sim_args.experiment_config(experiment_name)\n",
    "    elif dataset_name == 'pres_zcity':\n",
    "        experiment_args = pres_zcity_args.experiment_config(experiment_name)\n",
    "    halrtc_dataComplete = HaLRTC_dataComplete(dataset_name, experiment_name, experiment_args)\n",
    "    halrtc_dataComplete.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 60% Random Missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'random_0.6'\n",
    "dataset_name_list = ['flow_sim', 'flow_zcity', 'pres_sim', 'pres_zcity']\n",
    "\n",
    "for dataset_name in dataset_name_list:\n",
    "    \n",
    "    if dataset_name == 'flow_sim':\n",
    "        experiment_args = flow_sim_args.experiment_config(experiment_name)\n",
    "    elif dataset_name == 'flow_zcity':\n",
    "        experiment_args = flow_zcity_args.experiment_config(experiment_name)\n",
    "    elif dataset_name == 'pres_sim':\n",
    "        experiment_args = pres_sim_args.experiment_config(experiment_name)\n",
    "    elif dataset_name == 'pres_zcity':\n",
    "        experiment_args = pres_zcity_args.experiment_config(experiment_name)\n",
    "    halrtc_dataComplete = HaLRTC_dataComplete(dataset_name, experiment_name, experiment_args)\n",
    "    halrtc_dataComplete.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 90% Random Missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'random_0.9'\n",
    "dataset_name_list = ['flow_sim', 'flow_zcity', 'pres_sim', 'pres_zcity']\n",
    "\n",
    "for dataset_name in dataset_name_list:\n",
    "    \n",
    "    if dataset_name == 'flow_sim':\n",
    "        experiment_args = flow_sim_args.experiment_config(experiment_name)\n",
    "    elif dataset_name == 'flow_zcity':\n",
    "        experiment_args = flow_zcity_args.experiment_config(experiment_name)\n",
    "    elif dataset_name == 'pres_sim':\n",
    "        experiment_args = pres_sim_args.experiment_config(experiment_name)\n",
    "    elif dataset_name == 'pres_zcity':\n",
    "        experiment_args = pres_zcity_args.experiment_config(experiment_name)\n",
    "    halrtc_dataComplete = HaLRTC_dataComplete(dataset_name, experiment_name, experiment_args)\n",
    "    halrtc_dataComplete.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 30% Long-Range Missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'long_range_0.3'\n",
    "dataset_name_list = ['flow_sim', 'flow_zcity', 'pres_sim', 'pres_zcity']\n",
    "\n",
    "for dataset_name in dataset_name_list:\n",
    "    \n",
    "    if dataset_name == 'flow_sim':\n",
    "        experiment_args = flow_sim_args.experiment_config(experiment_name)\n",
    "    elif dataset_name == 'flow_zcity':\n",
    "        experiment_args = flow_zcity_args.experiment_config(experiment_name)\n",
    "    elif dataset_name == 'pres_sim':\n",
    "        experiment_args = pres_sim_args.experiment_config(experiment_name)\n",
    "    elif dataset_name == 'pres_zcity':\n",
    "        experiment_args = pres_zcity_args.experiment_config(experiment_name)\n",
    "    halrtc_dataComplete = HaLRTC_dataComplete(dataset_name, experiment_name, experiment_args)\n",
    "    halrtc_dataComplete.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 60% Long-Range Missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'long_range_0.6'\n",
    "dataset_name_list = ['flow_sim', 'flow_zcity', 'pres_sim', 'pres_zcity']\n",
    "\n",
    "for dataset_name in dataset_name_list:\n",
    "    \n",
    "    if dataset_name == 'flow_sim':\n",
    "        experiment_args = flow_sim_args.experiment_config(experiment_name)\n",
    "    elif dataset_name == 'flow_zcity':\n",
    "        experiment_args = flow_zcity_args.experiment_config(experiment_name)\n",
    "    elif dataset_name == 'pres_sim':\n",
    "        experiment_args = pres_sim_args.experiment_config(experiment_name)\n",
    "    elif dataset_name == 'pres_zcity':\n",
    "        experiment_args = pres_zcity_args.experiment_config(experiment_name)\n",
    "    halrtc_dataComplete = HaLRTC_dataComplete(dataset_name, experiment_name, experiment_args)\n",
    "    halrtc_dataComplete.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 30% Block Missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'block_0.3'\n",
    "dataset_name_list = ['flow_sim', 'flow_zcity', 'pres_sim', 'pres_zcity']\n",
    "\n",
    "for dataset_name in dataset_name_list:\n",
    "    \n",
    "    if dataset_name == 'flow_sim':\n",
    "        experiment_args = flow_sim_args.experiment_config(experiment_name)\n",
    "    elif dataset_name == 'flow_zcity':\n",
    "        experiment_args = flow_zcity_args.experiment_config(experiment_name)\n",
    "    elif dataset_name == 'pres_sim':\n",
    "        experiment_args = pres_sim_args.experiment_config(experiment_name)\n",
    "    elif dataset_name == 'pres_zcity':\n",
    "        experiment_args = pres_zcity_args.experiment_config(experiment_name)\n",
    "    halrtc_dataComplete = HaLRTC_dataComplete(dataset_name, experiment_name, experiment_args)\n",
    "    halrtc_dataComplete.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7 60% Block Missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'block_0.6'\n",
    "dataset_name_list = ['flow_sim', 'flow_zcity', 'pres_sim', 'pres_zcity']\n",
    "\n",
    "for dataset_name in dataset_name_list:\n",
    "    \n",
    "    if dataset_name == 'flow_sim':\n",
    "        experiment_args = flow_sim_args.experiment_config(experiment_name)\n",
    "    elif dataset_name == 'flow_zcity':\n",
    "        experiment_args = flow_zcity_args.experiment_config(experiment_name)\n",
    "    elif dataset_name == 'pres_sim':\n",
    "        experiment_args = pres_sim_args.experiment_config(experiment_name)\n",
    "    elif dataset_name == 'pres_zcity':\n",
    "        experiment_args = pres_zcity_args.experiment_config(experiment_name)\n",
    "    halrtc_dataComplete = HaLRTC_dataComplete(dataset_name, experiment_name, experiment_args)\n",
    "    halrtc_dataComplete.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.8 30% Mix Missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'mix_0.3'\n",
    "dataset_name_list = ['flow_sim', 'flow_zcity', 'pres_sim', 'pres_zcity']\n",
    "\n",
    "for dataset_name in dataset_name_list:\n",
    "    \n",
    "    if dataset_name == 'flow_sim':\n",
    "        experiment_args = flow_sim_args.experiment_config(experiment_name)\n",
    "    elif dataset_name == 'flow_zcity':\n",
    "        experiment_args = flow_zcity_args.experiment_config(experiment_name)\n",
    "    elif dataset_name == 'pres_sim':\n",
    "        experiment_args = pres_sim_args.experiment_config(experiment_name)\n",
    "    elif dataset_name == 'pres_zcity':\n",
    "        experiment_args = pres_zcity_args.experiment_config(experiment_name)\n",
    "    halrtc_dataComplete = HaLRTC_dataComplete(dataset_name, experiment_name, experiment_args)\n",
    "    halrtc_dataComplete.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.9 50% Mix Missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'mix_0.5'\n",
    "dataset_name_list = ['flow_sim', 'flow_zcity', 'pres_sim', 'pres_zcity']\n",
    "\n",
    "for dataset_name in dataset_name_list:\n",
    "    \n",
    "    if dataset_name == 'flow_sim':\n",
    "        experiment_args = flow_sim_args.experiment_config(experiment_name)\n",
    "    elif dataset_name == 'flow_zcity':\n",
    "        experiment_args = flow_zcity_args.experiment_config(experiment_name)\n",
    "    elif dataset_name == 'pres_sim':\n",
    "        experiment_args = pres_sim_args.experiment_config(experiment_name)\n",
    "    elif dataset_name == 'pres_zcity':\n",
    "        experiment_args = pres_zcity_args.experiment_config(experiment_name)\n",
    "    halrtc_dataComplete = HaLRTC_dataComplete(dataset_name, experiment_name, experiment_args)\n",
    "    halrtc_dataComplete.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.10 70% Mix Missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'mix_0.7'\n",
    "dataset_name_list = ['flow_sim', 'flow_zcity', 'pres_sim', 'pres_zcity']\n",
    "\n",
    "for dataset_name in dataset_name_list:\n",
    "    \n",
    "    if dataset_name == 'flow_sim':\n",
    "        experiment_args = flow_sim_args.experiment_config(experiment_name)\n",
    "    elif dataset_name == 'flow_zcity':\n",
    "        experiment_args = flow_zcity_args.experiment_config(experiment_name)\n",
    "    elif dataset_name == 'pres_sim':\n",
    "        experiment_args = pres_sim_args.experiment_config(experiment_name)\n",
    "    elif dataset_name == 'pres_zcity':\n",
    "        experiment_args = pres_zcity_args.experiment_config(experiment_name)\n",
    "    halrtc_dataComplete = HaLRTC_dataComplete(dataset_name, experiment_name, experiment_args)\n",
    "    halrtc_dataComplete.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
