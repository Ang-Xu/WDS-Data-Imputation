{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from _utils import *\n",
    "from config import *\n",
    "\n",
    "import time\n",
    "import argparse\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import sparse\n",
    "from scipy.sparse.linalg import spsolve as spsolve\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class args_config():\n",
    "    def __init__(self, dataset_name):\n",
    "        self.model_name = 'LATC_NN'\n",
    "        self.model_result_save_path = os.path.join(result_folder_path, self.model_name)  \n",
    "        create_folder(self.model_result_save_path)\n",
    "\n",
    "        self.dataset_name = dataset_name\n",
    "        self.dataset_result_save_path = os.path.join(self.model_result_save_path, self.dataset_name) \n",
    "        create_folder(self.dataset_result_save_path)\n",
    "    \n",
    "    def experiment_config(self, experiment_name):  \n",
    "        self.experiment_result_save_path = os.path.join(self.dataset_result_save_path, experiment_name)\n",
    "        create_folder(self.experiment_result_save_path)\n",
    "\n",
    "        data_complete_path = os.path.join(self.experiment_result_save_path, 'data_complete')  \n",
    "        best_data_complete_path = os.path.join(self.experiment_result_save_path, 'best_data_complete.csv')\n",
    "        metrics_analysis_path = os.path.join(self.experiment_result_save_path, 'metrics_analysis')  \n",
    "        plt_result_path = os.path.join(self.experiment_result_save_path, 'plt_result.png')\n",
    "        best_args_path = os.path.join(self.experiment_result_save_path, 'best_args_config.yml')\n",
    "        final_complete_save_path = os.path.join(self.experiment_result_save_path, 'final_complete.csv')\n",
    "        create_folder([data_complete_path, metrics_analysis_path])\n",
    "        \n",
    "        parser = argparse.ArgumentParser(description='data complete configs')\n",
    "        parser.add_argument('--data_complete_path', type=str, default=data_complete_path)\n",
    "        parser.add_argument('--best_data_complete_path', type=str, default=best_data_complete_path)\n",
    "        parser.add_argument('--metrics_analysis_path', type=str, default=metrics_analysis_path)\n",
    "        parser.add_argument('--plt_result_path', type=str, default=plt_result_path)\n",
    "        parser.add_argument('--best_args_path', type=str, default=best_args_path)\n",
    "        parser.add_argument('--final_complete_save_path', type=str, default=final_complete_save_path)\n",
    "        args = parser.parse_known_args()[0]\n",
    "        return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_sim_args = args_config('flow_sim')\n",
    "flow_zcity_args = args_config('flow_zcity')\n",
    "pres_sim_args = args_config('pres_sim')\n",
    "pres_zcity_args = args_config('pres_zcity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_Psi(dim_time, time_lags):  \n",
    "    Psis = []\n",
    "    max_lag = np.max(time_lags)\n",
    "    for i in range(len(time_lags) + 1):\n",
    "        row = np.arange(0, dim_time - max_lag)  \n",
    "        if i == 0:\n",
    "            col = np.arange(0, dim_time - max_lag) + max_lag\n",
    "        else:\n",
    "            col = np.arange(0, dim_time - max_lag) + max_lag - time_lags[i - 1]\n",
    "        data = np.ones(dim_time - max_lag)\n",
    "        Psi = sparse.coo_matrix((data, (row, col)), shape = (dim_time - max_lag, dim_time))\n",
    "        Psis.append(Psi)\n",
    "    return Psis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_result(it, tol, var, var_hat):\n",
    "    print('Iter: {}'.format(it))\n",
    "    print('Tolerance: {:.6}'.format(tol))\n",
    "    num = len(var)\n",
    "    mape = compute_mape(var, var_hat)\n",
    "    rmse = compute_rmse(var, var_hat)\n",
    "    smape = compute_smape(var, var_hat)\n",
    "    print('complete Num: {}'.format(num))\n",
    "    print('complete MAPE: {:.6}'.format(mape))\n",
    "    print('complete RMSE: {:.6}'.format(rmse))\n",
    "    print('complete SMAPE: {:.6}'.format(smape))\n",
    "    return mape, rmse, smape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_analysis(mape_lists, rmse_lists, smape_lists, args, c_search_space):\n",
    "    mape_df = pd.DataFrame(mape_lists, index=c_search_space, columns=['mape'])\n",
    "    rmse_df = pd.DataFrame(rmse_lists, index=c_search_space, columns=['rmse'])\n",
    "    smape_df = pd.DataFrame(smape_lists, index=c_search_space, columns=['smape'])\n",
    "    mape_df.to_csv(os.path.join(args.metrics_analysis_path, 'mape_all_sensors.csv'), index=True, header=True)\n",
    "    rmse_df.to_csv(os.path.join(args.metrics_analysis_path, 'rmse_all_sensors.csv'), index=True, header=True)\n",
    "    smape_df.to_csv(os.path.join(args.metrics_analysis_path, 'smape_all_sensors.csv'), index=True, header=True)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_true_metrics(raw_data_value, denorm_sparse_value, denorm_data_complete_value):\n",
    "    pos_test = np.where((raw_data_value != 0) & (denorm_sparse_value == 0))\n",
    "    true_mape = compute_mape(raw_data_value[pos_test], denorm_data_complete_value[pos_test])\n",
    "    true_rmse = compute_rmse(raw_data_value[pos_test], denorm_data_complete_value[pos_test])\n",
    "    true_smape = compute_smape(raw_data_value[pos_test], denorm_data_complete_value[pos_test])\n",
    "    return true_mape, true_rmse, true_smape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_data_after_preprocess(best_data_complete_path, data_after_preprocess_path, data_after_complete_path):\n",
    "    best_data_complete_df = read_csv_data(best_data_complete_path)\n",
    "    data_after_preprocess_df = read_csv_data(data_after_preprocess_path)\n",
    "    data_after_preprocess_df = data_after_preprocess_df.astype('float64')\n",
    "   \n",
    "    zero_indices = np.where(data_after_preprocess_df == 0)\n",
    "    zero_indices = list(zip(zero_indices[0], zero_indices[1]))\n",
    "    for zero_index in zero_indices:\n",
    "        data_after_preprocess_df.iloc[zero_index[0], zero_index[1]] = best_data_complete_df.iloc[zero_index[0], zero_index[1]]\n",
    "    data_after_preprocess_df.to_csv(data_after_complete_path, index=True, header=True)\n",
    "    print('Data after complete saved in {}'.format(data_after_complete_path))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svt(mat, tau):\n",
    "    [m,n] = mat.shape\n",
    "    if 2 * m < n:\n",
    "        u, s, v = np.linalg.svd(mat @ mat.T, full_matrices = 0)\n",
    "        s = np.sqrt(s)\n",
    "        tol = n * np.finfo(float).eps * np.max(s)\n",
    "        idx = np.sum(s > max(tau, tol))\n",
    "        mid = (s[:idx] - tau) / s[:idx]\n",
    "        return (u[:,:idx] @ np.diag(mid)) @ (u[:,:idx].T @ mat)\n",
    "    elif m > 2 * n:\n",
    "        return svt(mat.T, tau).T\n",
    "    u, s, v = np.linalg.svd(mat, full_matrices = 0)\n",
    "    idx = np.sum(s > tau)\n",
    "    return u[:,:idx] @ np.diag(s[:idx]-tau) @ v[:idx,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def latc(dense_tensor, sparse_tensor, time_lags, alpha, rho0, lambda0, \n",
    "         epsilon = 1e-4, maxiter = 100, K = 3):\n",
    "    \"\"\"Low-Rank Autoregressive Tensor Completion (LATC)\"\"\"\n",
    "    \n",
    "    dim = np.array(sparse_tensor.shape)\n",
    "    dim_time = int(np.prod(dim) / dim[0])\n",
    "    d = len(time_lags)\n",
    "    max_lag = np.max(time_lags)\n",
    "    sparse_mat = ten2mat(sparse_tensor, 0)\n",
    "    pos_missing = np.where(sparse_mat == 0)  \n",
    "    pos_test = np.where((dense_tensor != 0) & (sparse_tensor == 0))  \n",
    "    dense_test = dense_tensor[pos_test]\n",
    "    del dense_tensor\n",
    "    \n",
    "    T = np.zeros(dim)\n",
    "    Z_tensor = sparse_tensor.copy() \n",
    "    Z = sparse_mat.copy()\n",
    "    A = 0.001 * np.random.rand(dim[0], d)\n",
    "    Psis = generate_Psi(dim_time, time_lags)\n",
    "    \n",
    "    iden = sparse.coo_matrix((np.ones(dim_time), (np.arange(0, dim_time), np.arange(0, dim_time))), shape = (dim_time, dim_time))\n",
    "    it = 0\n",
    "    ind = np.zeros((d, dim_time - max_lag), dtype = np.int_)\n",
    "    for i in range(d):\n",
    "        ind[i, :] = np.arange(max_lag - time_lags[i], dim_time - time_lags[i])\n",
    "    last_mat = sparse_mat.copy()\n",
    "    snorm = np.linalg.norm(sparse_mat, 'fro')\n",
    "    rho = rho0\n",
    "    while True:\n",
    "        temp = []\n",
    "        for m in range(dim[0]):\n",
    "            Psis0 = Psis.copy()\n",
    "            for i in range(d):\n",
    "                Psis0[i + 1] = A[m, i] * Psis[i + 1]\n",
    "            B = Psis0[0] - sum(Psis0[1 :])\n",
    "            temp.append(B.T @ B)\n",
    "        for k in range(K):\n",
    "            rho = min(rho * 1.05, 1e5)\n",
    "            tensor_hat = np.zeros(dim)\n",
    "            for p in range(len(dim)):\n",
    "                tensor_hat += alpha[p] * mat2ten(svt(ten2mat(Z_tensor - T / rho, p), alpha[p] / rho), dim, p)\n",
    "            temp0 = rho / lambda0 * ten2mat(tensor_hat + T / rho, 0)\n",
    "            mat = np.zeros((dim[0], dim_time))\n",
    "            for m in range(dim[0]):\n",
    "                mat[m, :] = spsolve(temp[m] + rho * iden / lambda0, temp0[m, :])\n",
    "            Z[pos_missing] = mat[pos_missing]\n",
    "            Z_tensor = mat2ten(Z, dim, 0)\n",
    "            T = T + rho * (tensor_hat - Z_tensor)\n",
    "        for m in range(dim[0]):\n",
    "            A[m, :] = np.linalg.lstsq(Z[m, ind].T, Z[m, max_lag :], rcond = None)[0]\n",
    "\n",
    "        mat_hat = ten2mat(tensor_hat, 0)\n",
    "        tol = np.linalg.norm((mat_hat - last_mat), 'fro') / snorm\n",
    "        last_mat = mat_hat.copy()\n",
    "        it += 1\n",
    "        if (tol < epsilon) or (it >= maxiter):\n",
    "            break\n",
    "    \n",
    "    tensor_hat[tensor_hat < 1] = 1  \n",
    "    print_result(it, tol, dense_test, tensor_hat[pos_test]) \n",
    "    return tensor_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LATC_dataComplete():\n",
    "\n",
    "    def __init__(self, dataset_name, experiment_name, c_search_space, experiment_args):\n",
    "        if dataset_name == 'flow_sim':\n",
    "            self.raw_dataset_path = flow_sim_path\n",
    "        elif dataset_name == 'pres_sim':\n",
    "            self.raw_dataset_path = pres_sim_path\n",
    "        elif dataset_name == 'flow_zcity':\n",
    "            self.raw_dataset_path = flow_zcity_path\n",
    "        elif dataset_name == 'pres_zcity':\n",
    "            self.raw_dataset_path = pres_zcity_path\n",
    "\n",
    "        self.raw_data_df = read_csv_data(self.raw_dataset_path)\n",
    "        self.c_search_space = c_search_space\n",
    "        self.experiment_args = experiment_args\n",
    "        \n",
    "        self.data_norm_for_completing_path = os.path.join(dataset_sparse_path, dataset_name, 'data_norm_for_completing.csv')\n",
    "        self.sparse_mat_for_completing_path = os.path.join(dataset_sparse_path, dataset_name, experiment_name, 'sparse_mat_for_completing.csv')\n",
    "        self.denorm_sparse_for_completing_path = os.path.join(dataset_sparse_path, dataset_name, experiment_name, 'denorm_sparse_for_completing.csv')\n",
    "\n",
    "        self.data_complete_path = self.experiment_args.data_complete_path\n",
    "        self.best_data_complete_path = self.experiment_args.best_data_complete_path\n",
    "        self.metrics_analysis_path = self.experiment_args.metrics_analysis_path\n",
    "        self.plt_result_path = self.experiment_args.plt_result_path\n",
    "        self.best_args_path = self.experiment_args.best_args_path\n",
    "        self.final_complete_save_path = self.experiment_args.final_complete_save_path\n",
    "\n",
    "        self._prepareForImputation()\n",
    "        return\n",
    "    \n",
    "    def _prepareForImputation(self):\n",
    "        self.norm_data_df = read_csv_data(self.data_norm_for_completing_path)\n",
    "        self.dense_mat = self.norm_data_df.values\n",
    "        self.dense_tensor = self.dense_mat.T.reshape([self.dense_mat.shape[1], -1, int(24*60/15)]).transpose(0, 2, 1)\n",
    "\n",
    "        self.sparse_mat_df = read_csv_data(self.sparse_mat_for_completing_path)\n",
    "        self.sparse_mat = self.sparse_mat_df.T.values\n",
    "        self.sparse_tensor = self.sparse_mat.reshape([self.dense_mat.shape[1], -1, int(24*60/15)]).transpose(0, 2, 1)\n",
    "        self.denorm_sparse_mat_df = read_csv_data(self.denorm_sparse_for_completing_path)\n",
    "        return\n",
    "\n",
    "    def latc_complete(self):\n",
    "       \n",
    "        mape_all_sensors_lists = []\n",
    "        rmse_all_sensors_lists = []\n",
    "        smape_all_sensors_lists = []\n",
    "        mape_single_sensor_df = pd.DataFrame(columns=self.raw_data_df.columns)\n",
    "        rmse_single_sensor_df = pd.DataFrame(columns=self.raw_data_df.columns)\n",
    "        smape_single_sensor_df = pd.DataFrame(columns=self.raw_data_df.columns)\n",
    "        best_rmse = np.inf  \n",
    "        best_c = None\n",
    "        best = False\n",
    "        current_epoch = 1\n",
    "        total_epoch = len(self.c_search_space)\n",
    "        for c in self.c_search_space:\n",
    "            mape_all_sensors_list = []\n",
    "            rmse_all_sensors_list = []\n",
    "            smape_all_sensors_list = []\n",
    "            start = time.time()\n",
    "            time_lags = np.arange(1, 7)\n",
    "            alpha = np.ones(3) / 3\n",
    "            rho = 1e-5\n",
    "            lambda0 = c * rho\n",
    "            print('epoch: %d/%d, c: %.2f' % (current_epoch, total_epoch, c))\n",
    "            self.tensor_hat = latc(self.dense_tensor, self.sparse_tensor, time_lags, alpha, rho, lambda0)\n",
    "            self.mat_hat = ten2mat(self.tensor_hat, 0)\n",
    "            self.data_complete_df = pd.DataFrame(self.mat_hat.T, index=self.norm_data_df.index, columns=self.norm_data_df.columns)\n",
    "            self.denorm_data_complete_df = reverse_one2hundred_normalization(self.data_complete_df, self.raw_data_df)\n",
    "            save_path = os.path.join(self.data_complete_path, 'c=' + str(c) + '.csv')\n",
    "            \n",
    "            self.denorm_data_complete_df = self.denorm_data_complete_df.round(3)\n",
    "            self.denorm_data_complete_df.to_csv(save_path, index=True, header=True)\n",
    "\n",
    "            mape_all_sensors, rmse_all_sensors, smape_all_sensors = compute_true_metrics(self.raw_data_df.values, self.denorm_sparse_mat_df.values, self.denorm_data_complete_df.values)  \n",
    "            print('MAPE: %.6f, RMSE: %.6f, SMAPE: %.6f' % (mape_all_sensors, rmse_all_sensors, smape_all_sensors))\n",
    "            if rmse_all_sensors < best_rmse:\n",
    "                best_rmse = rmse_all_sensors\n",
    "                best_c = c  \n",
    "                best = True\n",
    "            mape_all_sensors_list.append(mape_all_sensors)\n",
    "            rmse_all_sensors_list.append(rmse_all_sensors)\n",
    "            smape_all_sensors_list.append(smape_all_sensors)\n",
    "\n",
    "            if best:\n",
    "                self.denorm_data_complete_df.to_csv(self.best_data_complete_path, index=True, header=True)\n",
    "                best = False\n",
    "            mape_single_sensor_list, rmse_single_sensor_list, smape_single_sensor_list = result_analysis(self.raw_data_df, self.denorm_sparse_mat_df, self.denorm_data_complete_df)\n",
    "            mape_single_sensor_df.loc['c=' + str(c), :] = mape_single_sensor_list\n",
    "            rmse_single_sensor_df.loc['c=' + str(c), :] = rmse_single_sensor_list\n",
    "            smape_single_sensor_df.loc['c=' + str(c), :] = smape_single_sensor_list\n",
    "            end = time.time()\n",
    "            print('Running time: %d seconds\\n' %(end - start))\n",
    "            current_epoch += 1\n",
    "            mape_all_sensors_lists.append(mape_all_sensors_list)\n",
    "            rmse_all_sensors_lists.append(rmse_all_sensors_list)\n",
    "            smape_all_sensors_lists.append(smape_all_sensors_list)\n",
    "        mape_all_sensors_lists = np.array(mape_all_sensors_lists)\n",
    "        rmse_all_sensors_lists = np.array(rmse_all_sensors_lists)\n",
    "        smape_all_sensors_lists = np.array(smape_all_sensors_lists)\n",
    "        \n",
    "        metrics_analysis(mape_all_sensors_lists, rmse_all_sensors_lists, smape_all_sensors_lists, self.experiment_args, self.c_search_space)\n",
    "        mape_single_sensor_df.to_csv(os.path.join(self.metrics_analysis_path, 'mape_single_sensor.csv'), index=True, header=True)\n",
    "        rmse_single_sensor_df.to_csv(os.path.join(self.metrics_analysis_path, 'rmse_single_sensor.csv'), index=True, header=True)\n",
    "        smape_single_sensor_df.to_csv(os.path.join(self.metrics_analysis_path, 'smape_single_sensor.csv'), index=True, header=True)\n",
    "        \n",
    "        best_mape_single_sensor_list = mape_single_sensor_df.loc['c=' + str(best_c), :].values\n",
    "        best_rmse_single_sensor_list = rmse_single_sensor_df.loc['c=' + str(best_c), :].values\n",
    "        best_smape_single_sensor_list = smape_single_sensor_df.loc['c=' + str(best_c), :].values\n",
    "        return best_c, best_mape_single_sensor_list, best_rmse_single_sensor_list, best_smape_single_sensor_list\n",
    "    \n",
    "    def run(self):\n",
    "        print('\\n--------------------------- Beginning ---------------------------')\n",
    "        best_c, best_mape_single_sensor_list, best_rmse_single_sensor_list, best_smape_single_sensor_list = self.latc_complete()\n",
    "        \n",
    "        self.best_args_dict = {}\n",
    "        self.best_args_dict['best_c'] = best_c\n",
    "        write_yaml(self.best_args_path, self.best_args_dict)\n",
    "        fill_data_after_preprocess(self.best_data_complete_path, self.raw_dataset_path, self.final_complete_save_path)\n",
    "        plt_result(self.raw_data_df, read_csv_data(self.best_data_complete_path), self.denorm_sparse_mat_df, self.plt_result_path,\n",
    "                   best_mape_single_sensor_list, best_rmse_single_sensor_list, best_smape_single_sensor_list)\n",
    "        print('\\n--------------------------- Ending ---------------------------')         \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 30% Random Missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_type = 'random'\n",
    "missing_rate = 0.3\n",
    "experiment_name = missing_type + '_' + str(missing_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### flow_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_search_space = [1/10, 1/5, 1, 5, 10]\n",
    "dataset_name = 'flow_sim'\n",
    "\n",
    "experiment_args = flow_sim_args.experiment_config(experiment_name)\n",
    "Imputer = LATC_dataComplete(dataset_name, experiment_name, c_search_space, experiment_args)\n",
    "Imputer.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pres_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_search_space = [1/10, 1/5, 1, 5, 10]\n",
    "dataset_name = 'pres_sim'\n",
    "\n",
    "experiment_args = pres_sim_args.experiment_config(experiment_name)\n",
    "Imputer = LATC_dataComplete(dataset_name, experiment_name, c_search_space, experiment_args)\n",
    "Imputer.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### flow_zcity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_search_space = [1/10, 1/5, 1, 5, 10]\n",
    "dataset_name = 'flow_zcity'\n",
    "\n",
    "experiment_args = flow_zcity_args.experiment_config(experiment_name)\n",
    "Imputer = LATC_dataComplete(dataset_name, experiment_name, c_search_space, experiment_args)\n",
    "Imputer.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pres_zcity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_search_space = [1/10, 1/5, 1, 5, 10]\n",
    "dataset_name = 'pres_zcity'\n",
    "\n",
    "experiment_args = pres_zcity_args.experiment_config(experiment_name)\n",
    "Imputer = LATC_dataComplete(dataset_name, experiment_name, c_search_space, experiment_args)\n",
    "Imputer.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 60% Random Missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_type = 'random'\n",
    "missing_rate = 0.6\n",
    "experiment_name = missing_type + '_' + str(missing_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### flow_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_search_space = [1/10, 1/5, 1, 5, 10]\n",
    "dataset_name = 'flow_sim'\n",
    "\n",
    "experiment_args = flow_sim_args.experiment_config(experiment_name)\n",
    "Imputer = LATC_dataComplete(dataset_name, experiment_name, c_search_space, experiment_args)\n",
    "Imputer.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pres_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_search_space = [1/10, 1/5, 1, 5, 10]\n",
    "dataset_name = 'pres_sim'\n",
    "\n",
    "experiment_args = pres_sim_args.experiment_config(experiment_name)\n",
    "Imputer = LATC_dataComplete(dataset_name, experiment_name, c_search_space, experiment_args)\n",
    "Imputer.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### flow_zcity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_search_space = [1/10, 1/5, 1, 5, 10]\n",
    "dataset_name = 'flow_zcity'\n",
    "\n",
    "experiment_args = flow_zcity_args.experiment_config(experiment_name)\n",
    "Imputer = LATC_dataComplete(dataset_name, experiment_name, c_search_space, experiment_args)\n",
    "Imputer.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pres_zcity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_search_space = [1/10, 1/5, 1, 5, 10]\n",
    "dataset_name = 'pres_zcity'\n",
    "\n",
    "experiment_args = pres_zcity_args.experiment_config(experiment_name)\n",
    "Imputer = LATC_dataComplete(dataset_name, experiment_name, c_search_space, experiment_args)\n",
    "Imputer.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 30% Long-Range Missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_type = 'long_range'\n",
    "missing_rate = 0.3\n",
    "experiment_name = missing_type + '_' + str(missing_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### flow_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_search_space = [1/10, 1/5, 1, 5, 10]\n",
    "dataset_name = 'flow_sim'\n",
    "\n",
    "experiment_args = flow_sim_args.experiment_config(experiment_name)\n",
    "Imputer = LATC_dataComplete(dataset_name, experiment_name, c_search_space, experiment_args)\n",
    "Imputer.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pres_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_search_space = [1/10, 1/5, 1, 5, 10]\n",
    "dataset_name = 'pres_sim'\n",
    "\n",
    "experiment_args = pres_sim_args.experiment_config(experiment_name)\n",
    "Imputer = LATC_dataComplete(dataset_name, experiment_name, c_search_space, experiment_args)\n",
    "Imputer.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### flow_zcity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_search_space = [1/10, 1/5, 1, 5, 10]\n",
    "dataset_name = 'flow_zcity'\n",
    "\n",
    "experiment_args = flow_zcity_args.experiment_config(experiment_name)\n",
    "Imputer = LATC_dataComplete(dataset_name, experiment_name, c_search_space, experiment_args)\n",
    "Imputer.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pres_zcity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_search_space = [1/10, 1/5, 1, 5, 10]\n",
    "dataset_name = 'pres_zcity'\n",
    "\n",
    "experiment_args = pres_zcity_args.experiment_config(experiment_name)\n",
    "Imputer = LATC_dataComplete(dataset_name, experiment_name, c_search_space, experiment_args)\n",
    "Imputer.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 30% Block Missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_type = 'block'\n",
    "missing_rate = 0.3\n",
    "experiment_name = missing_type + '_' + str(missing_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### flow_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_search_space = [1/10, 1/5, 1, 5, 10]\n",
    "dataset_name = 'flow_sim'\n",
    "\n",
    "experiment_args = flow_sim_args.experiment_config(experiment_name)\n",
    "Imputer = LATC_dataComplete(dataset_name, experiment_name, c_search_space, experiment_args)\n",
    "Imputer.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pres_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_search_space = [1/10, 1/5, 1, 5, 10]\n",
    "dataset_name = 'pres_sim'\n",
    "\n",
    "experiment_args = pres_sim_args.experiment_config(experiment_name)\n",
    "Imputer = LATC_dataComplete(dataset_name, experiment_name, c_search_space, experiment_args)\n",
    "Imputer.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### flow_zcity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_search_space = [1/10, 1/5, 1, 5, 10]\n",
    "dataset_name = 'flow_zcity'\n",
    "\n",
    "experiment_args = flow_zcity_args.experiment_config(experiment_name)\n",
    "Imputer = LATC_dataComplete(dataset_name, experiment_name, c_search_space, experiment_args)\n",
    "Imputer.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pres_zcity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_search_space = [1/10, 1/5, 1, 5, 10]\n",
    "dataset_name = 'pres_zcity'\n",
    "\n",
    "experiment_args = pres_zcity_args.experiment_config(experiment_name)\n",
    "Imputer = LATC_dataComplete(dataset_name, experiment_name, c_search_space, experiment_args)\n",
    "Imputer.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 30% Mix Missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_type = 'mix'\n",
    "missing_rate = 0.3\n",
    "experiment_name = missing_type + '_' + str(missing_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### flow_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_search_space = [1/10, 1/5, 1, 5, 10]\n",
    "dataset_name = 'flow_sim'\n",
    "\n",
    "experiment_args = flow_sim_args.experiment_config(experiment_name)\n",
    "Imputer = LATC_dataComplete(dataset_name, experiment_name, c_search_space, experiment_args)\n",
    "Imputer.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pres_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_search_space = [1/10, 1/5, 1, 5, 10]\n",
    "dataset_name = 'pres_sim'\n",
    "\n",
    "experiment_args = pres_sim_args.experiment_config(experiment_name)\n",
    "Imputer = LATC_dataComplete(dataset_name, experiment_name, c_search_space, experiment_args)\n",
    "Imputer.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### flow_zcity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_search_space = [1/10, 1/5, 1, 5, 10]\n",
    "dataset_name = 'flow_zcity'\n",
    "\n",
    "experiment_args = flow_zcity_args.experiment_config(experiment_name)\n",
    "Imputer = LATC_dataComplete(dataset_name, experiment_name, c_search_space, experiment_args)\n",
    "Imputer.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pres_zcity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_search_space = [1/10, 1/5, 1, 5, 10]\n",
    "dataset_name = 'pres_zcity'\n",
    "\n",
    "experiment_args = pres_zcity_args.experiment_config(experiment_name)\n",
    "Imputer = LATC_dataComplete(dataset_name, experiment_name, c_search_space, experiment_args)\n",
    "Imputer.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 50% Mix Missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_type = 'mix'\n",
    "missing_rate = 0.5\n",
    "experiment_name = missing_type + '_' + str(missing_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### flow_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_search_space = [1/10, 1/5, 1, 5, 10]\n",
    "dataset_name = 'flow_sim'\n",
    "\n",
    "experiment_args = flow_sim_args.experiment_config(experiment_name)\n",
    "Imputer = LATC_dataComplete(dataset_name, experiment_name, c_search_space, experiment_args)\n",
    "Imputer.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pres_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_search_space = [1/10, 1/5, 1, 5, 10]\n",
    "dataset_name = 'pres_sim'\n",
    "\n",
    "experiment_args = pres_sim_args.experiment_config(experiment_name)\n",
    "Imputer = LATC_dataComplete(dataset_name, experiment_name, c_search_space, experiment_args)\n",
    "Imputer.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### flow_zcity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_search_space = [1/10, 1/5, 1, 5, 10]\n",
    "dataset_name = 'flow_zcity'\n",
    "\n",
    "experiment_args = flow_zcity_args.experiment_config(experiment_name)\n",
    "Imputer = LATC_dataComplete(dataset_name, experiment_name, c_search_space, experiment_args)\n",
    "Imputer.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pres_zcity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_search_space = [1/10, 1/5, 1, 5, 10]\n",
    "dataset_name = 'pres_zcity'\n",
    "\n",
    "experiment_args = pres_zcity_args.experiment_config(experiment_name)\n",
    "Imputer = LATC_dataComplete(dataset_name, experiment_name, c_search_space, experiment_args)\n",
    "Imputer.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
